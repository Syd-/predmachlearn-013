---
title: "Practical Machine Learning Project"
author: "Sid M"
output: pdf_document
---
# Prerequisites
- First,  download the [training data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) and [test data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv) and have placed them in the same directory as the R files.  
- Next, set the working directory to the place you have downloaded it to.  
- Ensure you have the following R packages installed: **caret**, **randomForest**

# Preprocessing
In this step, we:  
1. Read the raw csv from files we downloaded in prerequisites  
2. Remove features that have zero variance  
3. Remove the descriptive columns [1 - 7]  
4. Remove all columns that are NA  
```{r, cache=TRUE}
library(caret)
loadAndCleanCSV <- function(file) {
  raw <- read.csv(file)
  zeroVCols <- nearZeroVar(raw)
  raw <- raw[, -zeroVCols]
  raw <- raw[-(1:7)]
  naCols <- apply(raw, 2, function(x) { sum(is.na(x)) })
  return(raw[, which(naCols == 0)])
}
trainingData <- loadAndCleanCSV("pml-training.csv")
testData <- loadAndCleanCSV("pml-testing.csv")
```
We then partition the trainingData into a training and cross validation set. We set the seed to a constant number for the purposes of reproducibility.
```{r, cache=TRUE}
set.seed(1337)
trainingIndices <- createDataPartition(trainingData$classe, p = 0.8, list = FALSE)
trainingSet <- trainingData[trainingIndices, ]
crossValidationSet <- trainingData[-trainingIndices, ]
```
# Training the Model
We use the randomForest package for classification and regression.  
```{r, cache=TRUE}
library(randomForest)
model <- randomForest(classe ~ ., data = trainingSet)
```
Now that our model has been created, we use it to see how well we perform with cross validation.  

# Cross Validation accuracy (Out of Sample)
```{r, cache=TRUE}
OOSample <- predict(model, crossValidationSet)
confusionMatrix(OOSample, crossValidationSet$classe)
```
As can be seen, our accuracy with the Cross Validation is: **99.54%**.  
Thus, our out of sample error is **0.46%**.  
So far, our model proves that it is good, so we now run it on the test data.

# Test Set Prediction
```{r, cache=TRUE}
testPrediction <- predict(model, testData)
testPrediction
```
Finally, to conclude this assignment, we turn the prediction to a format that the submission page can accept given the *pml_write_files* function:
```{r, cache=TRUE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(as.vector(testPrediction))
```
